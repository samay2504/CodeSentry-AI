# AI Code Review Tool Environment Variables
# Copy this file to .env and fill in your values

# OpenAI API Configuration (Optional)
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Google AI API Configuration (Optional)
# Get your API key from https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Hugging Face API Configuration
# Get your API key from https://huggingface.co/settings/tokens
HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_key_here

# Groq API Configuration (Optional)
# Get your API key from https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here

# LLM Model Configuration
# Default model for code analysis and improvement
DEFAULT_LLM_MODEL=bigcode/starcoder

# LLM Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048
LLM_TIMEOUT=30
LLM_RETRY_ATTEMPTS=3
LLM_FALLBACK_ENABLED=true

# Alternative models you can use:
# - bigcode/starcoder (recommended - code-focused and fully supported)
# - microsoft/DialoGPT-medium
# - gpt2
# - facebook/opt-350m
# - bigscience/bloom-560m

# Google Cloud Platform Configuration (Optional)
# For additional cloud features like logging and storage
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/credentials.json
GCP_PROJECT_ID=your_gcp_project_id

# Database Configuration
# SQLite database path (default: database.db in project root)
DATABASE_PATH=database.db

# Logging Configuration
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
# Log file path (optional)
LOG_FILE_PATH=./logs/ai_reviewer.log
# Log file size limit in MB
LOG_MAX_FILE_SIZE_MB=10
# Number of log backup files
LOG_BACKUP_COUNT=5
# Use JSON format for logs
LOG_JSON_FORMAT=true

# Output Configuration
# Default output directory for improved code
DEFAULT_OUTPUT_DIR=./output

# Default report format: markdown, json, html
DEFAULT_REPORT_FORMAT=markdown

# Create backup of original files
CREATE_BACKUP=true

# Include metrics in reports
INCLUDE_METRICS=true

# Include summary in reports
INCLUDE_SUMMARY=true

# Performance Configuration
# Maximum number of files to process in parallel
MAX_PARALLEL_FILES=5

# Analysis Configuration
# Maximum file size to process (in MB)
MAX_FILE_SIZE_MB=10

# Code chunking configuration
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# Security Configuration
# Enable/disable security analysis
ENABLE_SECURITY_ANALYSIS=true

# Enable/disable performance analysis
ENABLE_PERFORMANCE_ANALYSIS=true

# Enable/disable maintainability analysis
ENABLE_MAINTAINABILITY_ANALYSIS=true

# Enable/disable readability analysis
ENABLE_READABILITY_ANALYSIS=true

# Security settings
MASK_API_KEYS=true
SANITIZE_LOGS=true
VALIDATE_INPUTS=true
MAX_INPUT_SIZE_MB=50

# File Type Configuration
# Supported code file extensions (comma-separated)
SUPPORTED_EXTENSIONS=.py,.js,.ts,.jsx,.tsx,.html,.css,.scss,.java,.cpp,.c,.h,.hpp,.cs,.php,.rb,.go,.rs,.swift,.kt,.scala,.clj,.hs,.ml,.fs,.sql,.sh,.bat,.ps1,.yaml,.yml,.json,.xml,.md,.txt,.ini,.cfg,.conf

# Ignore patterns for files and directories (comma-separated)
IGNORE_PATTERNS=.git,.svn,.hg,__pycache__,node_modules,.venv,venv,env,.env,build,dist,target,bin,obj,.DS_Store,Thumbs.db,*.pyc,*.pyo,*.pyd,*.so,*.dll,*.exe,*.dylib,*.a,*.o

# Proxy Configuration (Optional)
# If you're behind a corporate proxy
#HTTP_PROXY=http://proxy.company.com:8080
#HTTPS_PROXY=https://proxy.company.com:8080

# Cache Configuration
# Enable caching for LLM responses
CACHE_ENABLED=true
CACHE_DIR=./cache

# Rate Limiting
# Maximum requests per minute to Hugging Face API
MAX_REQUESTS_PER_MINUTE=60

# Development Configuration
# Enable debug mode
DEBUG=false

# Enable verbose logging
VERBOSE=false 